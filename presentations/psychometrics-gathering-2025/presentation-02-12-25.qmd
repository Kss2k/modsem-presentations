---
title: "`modsem`: An R Package for Estimating Latent Interactions and Quadratic Effects"
author: "Kjell S Slupphaug"
format:
  beamer:
    mathspec: true
    header-includes:
          - \usepackage{bm}
    theme: default 
    colortheme: dove
    fonttheme: structuresmallcapsserif
bibliography: references.bib
---


```{r, setup, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo=TRUE)

library(modsem)
library(lavaan)
library(semTools)
library(nlsem)

# Overload lavaan objects and modsem objects
sem <- function(...) {
  out <- list(result = lavaan::sem(...))
  class(out) <- "presentation_result"
  out
}


modsem <- function(model.syntax, data, method = "dblcent", ...) {
  mp <- tryCatch(MplusAutomation::detectMplus(), error = \(e) "none")
  
  if (tolower(mp) != "mplus" && tolower(method) == "mplus") {
    # If we don't have Mplus, or we only have the demo version
    # we switch to the LMS approach. For all the examples in this
    # presentation, both the LMS approach in modsem, and the LMS
    # approach in Mplus, yield the same results (within 3 decimal points).
    # So while this is not kosher, it doesn't change the presentation
    # and allows the presentation to be compiled even if you don't have
    # the full version of Mplus.
    method <- "lms"
  }


  out <- list(result = modsem::modsem(model.syntax = model.syntax, data = data,
                                      method = method, ...))
  class(out) <- "presentation_result"
  out
}


# Get pretty output
summary.presentation_result <- function(object, ...) {
  lines <- capture.output(summary(object$result, ...))

  cat("Truncated Output:\n")
  breaks <- which(grepl("^\\s*$", lines))
  start  <- which(grepl("Regressions:", lines))
  end    <- min(breaks[breaks > start]) - 1L

  cat(lines[start:end], sep = "\n")
}


plot_interaction <- function(model, ...) {
  modsem::plot_interaction(model = model$result, ...) 
}


plot_jn <- function(model, ...) {
  modsem::plot_jn(model$result, ...) 
}


plot_surface <- function(model, ...) {
  modsem::plot_surface(model$result, ...) 
}


summary.emEst <- function(model) {
  tbl <- nlsem:::summary.emEst(model)$estimates
  idx <- rownames(tbl)
  cat("Truncated Output:\n")
  print(tbl[grepl("Gamma|Omega", idx), ])
}
```


## `modsem`

- `modsem` is an `R` package for estimating latent interaction and quadratic effects, in *Structural Equation Models* (SEMs).

## Frameworks

- Product Indicator (PI) approaches
- Distribution Analytic (DA) approaches

# Product Indicator (PI) Approaches
## Product Indicator (PI) Approaches

- First attempt at latent interaction in SEMs [@kenny_estimating_1984]
- Creates product indicators, used as indicators for latent interaction terms.
- Has traditionally required manual model specification, and manual construction
  of product indicators.
- Early approaches involved complicated model constraints.
- Manual specification (partially) led to a continual simplification of constraints.

## Product Indicator (PI) Approaches (History)

- Constrained Approach (orthogonal specification) [@kenny_estimating_1984]
- Constrained Approach (oblique specification) [@joreskog_nonlinear_1996]
- Constrained Approach (mean-centered indicators) [@algina_note_2001]
- Unconstrained Approach (constrained latent mean) [@martin_effect_1999]
- Resdiual Centering Approach (no constraints) [@little_merits_2006]
- Double Centering Approach (no constraints) [@lin_structural_2010]

## Product Indicator (PI) Approaches (Software)

- `semTools` offers tools for creating the product indicators, but does not help
  specify the model.
- Thus the PI approaches largely require manual specification.
- `modsem` automatically handles the creation of product indicators, and model
  specification.
- Model specification becomes exponentially more complicated for models with more
  indicators, more interaction terms. Especially for the PI approaches with model
  constraints.

## Example: Double Centering Approach, using `semTools`
\scriptsize

```{r}
model <- '
# Measurement Model
  X  =~ x1 + x2 + x3
  Z  =~ z1 + z2 + z3
  Y  =~ y1 + y2 + y3
  XZ =~ x1.z1 + x2.z1 + x3.z1 +
        x1.z2 + x2.z2 + x3.z2 +
        x1.z3 + x2.z3 + x3.z3

# Structural Model
  Y ~ X + Z + XZ

# Residual Covariances
  x1.z1 ~~ x1.z2 + x1.z3 + x2.z1 + x3.z1
  x1.z2 ~~ x1.z3 + x2.z2 + x3.z2
  x2.z1 ~~ x2.z2 + x2.z3 + x3.z1
  
  x1.z3 ~~ x2.z3 + x3.z3
  x2.z2 ~~ x2.z3 + x3.z2
  x3.z1 ~~ x3.z2 + x3.z3
  
  x2.z3 ~~ x3.z3
  x3.z2 ~~ x3.z3
'
```
\normalsize

## Example: Double Centering Approach, using `semTools`

\scriptsize
```{r}
library(semTools)
data.prod <- indProd(data = oneInt,
                     var1 = c("x1", "x2", "x3"),
                     var2 = c("z1", "z2", "z3"),
                     match = FALSE)

fit <- sem(model, data = data.prod)
summary(fit)
```
\normalsize

## Example: Double Centering Approach, using `modsem`

\scriptsize
```{r}
library(modsem)

model <- '
# Measurement Model
  X =~ x1 + x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

# Structural Model
  Y ~ X + Z + X:Z
'

fit <- modsem(model, data = oneInt)
summary(fit)
```
\normalsize


# Distribution Analytic (DA) Approaches
## Distribution Analytic (DA) Approaches

- Latent Moderated Structural Equations (LMS) Method, introduced by [@klein_maximum_2000].
- Quasi Maximum Likelihood (QML) Method, introducted by [@klein_quasi-maximum_2007].
- No formation of product indicators.
- Non-normal distribution of $\mathbf{\eta}$ is explicityly modelled.
- LMS and QML perform very similarily. But QML performs slightly better under
  normality violations.
- QML is less computationally intensive, with multiple moderators.

## Distribution Analytic (DA) Approaches (Software)

- `R` package `nlsem`.
- `Mplus`
- `modsem`

## `nlsem`

- Pros:
    - Free open source `R` package.
    - Has both LMS and QML approaches.

- Cons:
    - Very slow.
    - Hard to use.
    - Only handles models with a single endogenous variable ($\eta$).
    - Doesn't handle missing data.
    - Biased LMS standard errors.
    - Unstable estimates, sensitive to starting estimates.
    - Cannot produce standardized estimates.
    - Virtually no fit measures.
    - Does not handle linear and nonlinear constraints.
    - Generally unpolished.

## `Mplus`

- Pros:
    - Extended implementation of LMS approach (multiple endogenous variables, endogenous interactions).
    - Integrates well with other `Mplus` features (e.g., Multilevel SEM).
    - Handles three-way interaction terms.
    - Handles higher order models (and interactions).
    - Easy to use.
    - Full Information Maximum Likelihood (FIML) estimation.
    - Linear and nonlinear constraints.

- Cons:
    - Scales poorly with multiple interaction effects.
    - Does not include QML.
    - Proprietary (expensive) software package.
    - No Multigroup LMS.

## `modsem`

- Pros:
    - Free open source `R` package.
    - Extended implementation of LMS and QML approach (multiple endogenous variables, endogenous interactions).
    - Computational optimized implementation of LMS and QML approaches.
    - Better scaling in LMS approach, compared to `Mplus`.
    - Handles higher order models (and interactions).
    - Easy to use.
    - Full Information Maximum Likelihood (FIML) estimation.
    - Multigroup LMS and QML.
    - Linear and nonlinear constraints.
- Cons:
    - Missing some advanced features available in `Mplus` (e.g., Multilevel SEM).

## Example: LMS, `nlsem` (213.2 seconds)
\scriptsize
```{r}
library(nlsem)
set.seed(3248927)

model <- "
  X =~ x1 + x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

  Y ~ X + Z + X:Z
"

nlsem_model_1 <- lav2nlsem(model)
oneIntSorted <- oneInt[c("x1", "x2", "x3", "z1", "z2",
                         "z3", "y1", "y2", "y3")]
start <- runif(count_free_parameters(nlsem_model_1))

specs <- as.data.frame(nlsem_model_1)
specs[grepl("tau|alpha", specs$label), "class1"] <- 0
specs[grepl("nu\\.(x|y)", specs$label), "class1"] <- NA

nlsem_model_2 <- create_sem(specs)

fit_nlsem <- em(model = nlsem_model_2, data = oneIntSorted,
                convergence = 1e-4, max.iter = 500, start = start)
```
\normalsize


## Example: LMS, `nlsem` (213.2 seconds)

\scriptsize
```{r}
summary(fit_nlsem)
```
\normalsize

## Example: LMS, `Mplus` (4.2 seconds)

\scriptsize
```{r}
model <- '
# Measurement Model
  X  =~ x1 + x2 + x3
  Z  =~ z1 + z2 + z3
  Y  =~ y1 + y2 + y3

# Structural Model
  Y ~ X + Z + X:Z
'

fit <- modsem(model, data = oneInt, method = "mplus")
summary(fit)
```
\normalsize

## Example: LMS, `modsem` (1.2 seconds)

\scriptsize
```{r}
model <- '
# Measurement Model
  X  =~ x1 + x2 + x3
  Z  =~ z1 + z2 + z3
  Y  =~ y1 + y2 + y3

# Structural Model
  Y ~ X + Z + X:Z
'

fit <- modsem(model, data = oneInt, method = "lms")
summary(fit)
```
\normalsize


# Visualizing Interaction Effects

## Example Model
\scriptsize
```{r}
model <-  '
  visual  =~ x1 + x2 + x3
  textual =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9

  visual ~ speed + textual + speed:textual
'

fit <- modsem(model, data = HolzingerSwineford1939, method = "lms")
summary(fit)
```
\normalsize

## Plotting Margins (Simple Slopes)

\scriptsize
```{r}
plot_interaction(x = "speed", z = "textual", y = "visual", model = fit, vals_z = c(-2, 2))
```
\normalsize

## Johnson-Neyman Plot
\scriptsize
```{r}
plot_jn(x = "speed", z = "textual", y = "visual", model = fit, max_z = 6)
```
\normalsize

## Surface Plot
\scriptsize
```{r, eval = FALSE}
plot_surface(x = "speed", z = "textual", y = "visual", model = fit,
             colorscale = "Greys", grid = TRUE, grid_color = "black")
```
![](images/surface-plot-1.png){width=80%}
\normalsize

# Visualizing Models With Quadratic Effects
## Example Model
\scriptsize
```{r, echo = FALSE, }
set.seed(2934269)

var_X      <- 1
var_Z      <- 1
cov_X_Z    <- 0.2

zeta_Y     <- 0.4

gamma_Y_X  <-  0
gamma_Y_Z  <-  0
gamma_Y_XZ <-  1
gamma_Y_ZZ <-  3 # exclude for now
gamma_Y_XX <- -1 # exclude for now


lambda_1   <- 1
lambda_2   <- .7
lambda_3   <- .8


epsilon    <- 0.2
beta_1     <- 1.2
beta_2     <- 0.8
beta_3     <- 1.5
N          <- 1500

residual <- \(epsilon) rnorm(N, sd = sqrt(epsilon))
create_ind <- \(lv, beta, lambda, epsilon) beta + lambda * lv + residual(epsilon)


Phi <- matrix(c(var_X, cov_X_Z,
                cov_X_Z, var_Z), nrow = 2)
XI <- mvtnorm::rmvnorm(N, sigma = Phi)

X <- XI[, 1]
Z <- XI[, 2]

Y <-
  gamma_Y_X * X +
  gamma_Y_Z * Z +
  gamma_Y_XZ * X * Z +
  gamma_Y_XX * X * X +
  gamma_Y_ZZ * Z * Z +
  residual(zeta_Y)

x1 <- create_ind(X, beta_1, lambda_1, epsilon)
x2 <- create_ind(X, beta_2, lambda_2, epsilon)
x3 <- create_ind(X, beta_3, lambda_2, epsilon)

z1 <- create_ind(Z, beta_1, lambda_1, epsilon)
z2 <- create_ind(Z, beta_2, lambda_2, epsilon)
z3 <- create_ind(Z, beta_3, lambda_2, epsilon)

y1 <- create_ind(Y, beta_1, lambda_1, epsilon)
y2 <- create_ind(Y, beta_2, lambda_2, epsilon)
y3 <- create_ind(Y, beta_2, lambda_2, epsilon)


data.quadratic <- data.frame(
   x1, x2, x3,
   z1, z2, z3,
   y1, y2, y3
)
```

```{r}
model <- '
  X =~ x1 + x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

  Y ~ X + Z + X:X + Z:Z + X:Z
'

fit <- modsem(model, data = data.quadratic, method = "qml")
summary(fit)
```
\normalsize

## 2D Plot

\scriptsize
```{r}
plot_interaction(x = "X", z = "Z", y = "Y", model = fit, vals_z = c(-1, 0, 1))
```
\normalsize

## 3D (Response Surface) Plot

\scriptsize
```{r, eval = FALSE}
plot_surface(x = "X", z = "Z", y = "Y", model = fit,
            colorscale = "Greys", grid = TRUE, grid_color = "black")
```
![](images/surface-plot-2.png){width=80%}
\normalsize

\tiny
## References

