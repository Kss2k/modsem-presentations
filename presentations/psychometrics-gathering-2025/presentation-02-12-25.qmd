---
title: "`modsem`: An R Package for Estimating Latent Interactions and Quadratic Effects"
author: "Kjell S Slupphaug"
institute: "Norwegian University of Science and Technology (NTNU), Statistics Norway (SSB)."
format:
  beamer:
    mathspec: true
    header-includes:
          - \usepackage{bm}
    theme: default 
    colortheme: dove
    fonttheme: structuresmallcapsserif
bibliography: references.bib
---


```{r, setup, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo=TRUE)

library(modsem)
library(lavaan)
library(semTools)
library(nlsem)

# Overload lavaan objects and modsem objects
sem <- function(...) {
  out <- list(result = lavaan::sem(...))
  class(out) <- "presentation_result"
  out
}


modsem <- function(model.syntax, data, method = "dblcent", ...) {
  mp <- tryCatch(MplusAutomation::detectMplus(), error = \(e) "none")
  
  if (tolower(mp) != "mplus" && tolower(method) == "mplus") {
    # If we don't have Mplus, or we only have the demo version
    # we switch to the LMS approach. For all the examples in this
    # presentation, both the LMS approach in modsem, and the LMS
    # approach in Mplus, yield the same results (within 3 decimal points).
    # So while this is not kosher, it doesn't change the presentation
    # and allows the presentation to be compiled even if you don't have
    # the full version of Mplus.
    method <- "lms"
  }


  out <- list(result = modsem::modsem(model.syntax = model.syntax, data = data,
                                      method = method, ...))
  class(out) <- "presentation_result"
  out
}


# Get pretty output
summary.presentation_result <- function(object, ...) {
  lines <- capture.output(summary(object$result, ...))

  cat("Truncated Output:\n")
  breaks <- which(grepl("^\\s*$", lines))
  start  <- which(grepl("Regressions:", lines))
  end    <- min(breaks[breaks > start]) - 1L

  cat(lines[start:end], sep = "\n")
}


plot_interaction <- function(model, ...) {
  modsem::plot_interaction(model = model$result, ...) 
}


plot_jn <- function(model, ...) {
  modsem::plot_jn(model$result, ...) 
}


plot_surface <- function(model, ...) {
  modsem::plot_surface(model$result, ...) 
}


summary.emEst <- function(model) {
  tbl <- nlsem:::summary.emEst(model)$estimates
  idx <- rownames(tbl)
  cat("Truncated Output:\n")
  print(tbl[grepl("Gamma|Omega", idx), ])
}
```


## `modsem`

- `modsem` is an `R` package for estimating latent interaction and quadratic effects in *Structural Equation Models* (SEMs).
- Collection of approaches withing the Product Indicator (PI) and
  Distribution Analytic (DA) frameworks.
- Based on the `lavaan` package.

## Frameworks

- Product Indicator (PI) approaches
- Distribution Analytic (DA) approaches

# Product Indicator (PI) Approaches
## Product Indicator (PI) Approaches

- First attempt at latent interaction in SEMs [@kenny_estimating_1984].
- Creates product indicators that serve as indicators for latent interaction terms.
- Traditionally relies on manual model specification and construction of product indicators.
- Early implementations required complicated model constraints.
- Manual specification pressures have gradually simplified those constraints.

## Product Indicator (PI) Approaches

![](images/elemIntModel.png){width=80%}


## Product Indicator (PI) Approaches (History)

- Constrained Approach (orthogonal specification) [@kenny_estimating_1984].
- Constrained Approach (oblique specification) [@joreskog_nonlinear_1996].
- Constrained Approach (mean-centered indicators) [@algina_note_2001].
- Unconstrained Approach (constrained latent mean) [@martin_effect_1999].
- Residual Centering Approach (no constraints) [@little_merits_2006].
- Double Centering Approach (no constraints) [@lin_structural_2010].

## Product Indicator (PI) Approaches (Software)

- `semTools` automates creation of product indicators, but leaves model specification to the user.
- PI approaches therefore still involve error-prone manual setup.
- `modsem` creates the product indicators and model specification automatically.
- The model specification becomes increasingly complex for larger models, and
  more complicated model constraints.

## Example: Double Centering, `semTools`
\scriptsize

```{r}
model <- '
# Measurement Model
  X  =~ x1 + x2 + x3
  Z  =~ z1 + z2 + z3
  Y  =~ y1 + y2 + y3
  XZ =~ x1.z1 + x2.z1 + x3.z1 +
        x1.z2 + x2.z2 + x3.z2 +
        x1.z3 + x2.z3 + x3.z3

# Structural Model
  Y ~ X + Z + XZ

# Residual Covariances
  x1.z1 ~~ x1.z2 + x1.z3 + x2.z1 + x3.z1
  x1.z2 ~~ x1.z3 + x2.z2 + x3.z2
  x2.z1 ~~ x2.z2 + x2.z3 + x3.z1
  
  x1.z3 ~~ x2.z3 + x3.z3
  x2.z2 ~~ x2.z3 + x3.z2
  x3.z1 ~~ x3.z2 + x3.z3
  
  x2.z3 ~~ x3.z3
  x3.z2 ~~ x3.z3
'
```
\normalsize

## Example: Double Centering, `semTools`

\scriptsize
```{r}
library(semTools)
data.prod <- indProd(data = oneInt,
                     var1 = c("x1", "x2", "x3"),
                     var2 = c("z1", "z2", "z3"),
                     match = FALSE)

fit <- sem(model, data = data.prod)
summary(fit)
```
\normalsize

## Example: Double Centering, `modsem`

\scriptsize
```{r}
library(modsem)

model <- '
# Measurement Model
  X =~ x1 + x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

# Structural Model
  Y ~ X + Z + X:Z
'

fit <- modsem(model, data = oneInt)
summary(fit)
```
\normalsize


# Distribution Analytic (DA) Approaches
## Distribution Analytic (DA) Approaches

- Latent Moderated Structural Equations (LMS) method introduced by [@klein_maximum_2000].
- Quasi Maximum Likelihood (QML) method introduced by [@klein_quasi-maximum_2007].
- Avoids creating product indicators.
- Estimators in PI approaches (incorrectly) assume normally distributed interaction terms,
- and latent endogenous variables $\bm{\eta}$.
- Explicitly models the non-normal distribution of $\bm{\eta}$.
- LMS and QML perform similarly, although QML is slightly more robust under normality violations.
- QML scales better computationally when multiple moderators are involved.

## Distribution Analytic (DA) Approaches (Software)

- `R` package `nlsem`.
- `Mplus`.
- `modsem`.

## `nlsem`

- Pros:
    - Free, open-source `R` package.
    - Has both LMS and QML approaches.

- Cons:
    - Very slow.
    - Hard to use.
    - Only handles models with a single endogenous variable ($\eta$).
    - Doesn't handle missing data.
    - Biased LMS standard errors.
    - Unstable estimates, sensitive to starting estimates.
    - Cannot produce standardized estimates.
    - Virtually no fit measures.
    - Does not support linear and nonlinear constraints.
    - Generally unpolished.

## `Mplus`

- Pros:
    - User friendly.
    - Extended LMS implementation covering multiple endogenous variables and endogenous interactions.
    - Integrates with other `Mplus` features (e.g., multilevel SEM).
    - Handles three-way interactions and higher-order models.
    - Provides Full Information Maximum Likelihood (FIML) estimation.
    - Supports linear and nonlinear constraints.

- Cons:
    - Proprietary (expensive) software package.
    - Scales poorly with multiple interaction effects.
    - Does not include QML.
    - No multigroup LMS.

## `modsem`

- Pros:
    - Free, open-source `R` package.
    - User friendly.
    - Extended LMS and QML implementation (multiple endogenous variables, endogenous interactions).
    - Computationally optimized LMS and QML estimation.
    - Better LMS scaling relative to `Mplus`.
    - Supports higher-order models and interactions.
    - Provides Full Information Maximum Likelihood (FIML) estimation.
    - Supports linear and nonlinear constraints.
    - Offers multigroup LMS and QML.
- Cons:
    - Missing advanced features available in `Mplus` (e.g., multilevel SEM).

## Example: LMS, `nlsem` (213.2 seconds)
\scriptsize
```{r}
library(nlsem)
set.seed(3248927)

model <- "
  X =~ x1 + x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

  Y ~ X + Z + X:Z
"

nlsem_model_1 <- lav2nlsem(model)
oneIntSorted <- oneInt[c("x1", "x2", "x3", "z1", "z2",
                         "z3", "y1", "y2", "y3")]
start <- runif(count_free_parameters(nlsem_model_1))

specs <- as.data.frame(nlsem_model_1)
specs[grepl("tau|alpha", specs$label), "class1"] <- 0
specs[grepl("nu\\.(x|y)", specs$label), "class1"] <- NA

nlsem_model_2 <- create_sem(specs)

fit_nlsem <- em(model = nlsem_model_2, data = oneIntSorted,
                convergence = 1e-4, max.iter = 500, start = start)
```
\normalsize


## Example: LMS, `nlsem` (213.2 seconds)

\scriptsize
```{r}
summary(fit_nlsem)
```
\normalsize

## Example: LMS, `Mplus` (4.2 seconds)

\scriptsize
```{r, eval = FALSE}
ANALYSIS:
  ESTIMATOR = ML;
  TYPE = RANDOM;
  ALGORITHM = INTEGRATION;

MODEL:
  X BY x1-x3;
  Z BY z1-z3;
  Y BY y1-y3;
  Y ON X Z XZ;
  XZ | X XWITH Z;
```

```{r, echo = FALSE}
mplus_output <- "
MODEL RESULTS

                                                    Two-Tailed
                    Estimate       S.E.  Est./S.E.    P-Value
 Y          ON
    X                  0.673      0.031     21.674      0.000
    Z                  0.569      0.030     18.723      0.000
    XZ                 0.718      0.028     25.831      0.000
"

cat(mplus_output)
```
\normalsize

## Example: LMS, `modsem` (1.2 seconds)

\scriptsize
```{r}
model <- '
# Measurement Model
  X  =~ x1 + x2 + x3
  Z  =~ z1 + z2 + z3
  Y  =~ y1 + y2 + y3

# Structural Model
  Y ~ X + Z + X:Z
'

fit <- modsem(model, data = oneInt, method = "lms")
summary(fit)
```
\normalsize


# Visualizing Interaction Effects

## Example Model
\scriptsize
```{r}
model <-  '
  visual  =~ x1 + x2 + x3
  textual =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9

  visual ~ speed + textual + speed:textual
'

fit <- modsem(model, data = HolzingerSwineford1939, method = "lms")
summary(fit)
```
\normalsize

## Plotting Margins (Simple Slopes)

\scriptsize
```{r}
plot_interaction(x = "speed", z = "textual", y = "visual", model = fit, vals_z = c(-2, 2))
```
\normalsize

## Johnson-Neyman Plot
\scriptsize
```{r}
plot_jn(x = "speed", z = "textual", y = "visual", model = fit, max_z = 6)
```
\normalsize

## Surface Plot
\scriptsize
```{r, eval = FALSE}
plot_surface(x = "speed", z = "textual", y = "visual", model = fit,
             colorscale = "Greys", grid = TRUE, grid_color = "black")
```
![](images/surface-plot-1.png){width=80%}
\normalsize

# Visualizing Models With Quadratic Effects
## Example Model
\scriptsize
```{r, echo = FALSE, }
set.seed(2934269)

var_X      <- 1
var_Z      <- 1
cov_X_Z    <- 0.2

zeta_Y     <- 0.4

gamma_Y_X  <-  0
gamma_Y_Z  <-  0
gamma_Y_XZ <-  1
gamma_Y_ZZ <-  3 # exclude for now
gamma_Y_XX <- -1 # exclude for now


lambda_1   <- 1
lambda_2   <- .7
lambda_3   <- .8


epsilon    <- 0.2
beta_1     <- 1.2
beta_2     <- 0.8
beta_3     <- 1.5
N          <- 1500

residual <- \(epsilon) rnorm(N, sd = sqrt(epsilon))
create_ind <- \(lv, beta, lambda, epsilon) beta + lambda * lv + residual(epsilon)


Phi <- matrix(c(var_X, cov_X_Z,
                cov_X_Z, var_Z), nrow = 2)
XI <- mvtnorm::rmvnorm(N, sigma = Phi)

X <- XI[, 1]
Z <- XI[, 2]

Y <-
  gamma_Y_X * X +
  gamma_Y_Z * Z +
  gamma_Y_XZ * X * Z +
  gamma_Y_XX * X * X +
  gamma_Y_ZZ * Z * Z +
  residual(zeta_Y)

x1 <- create_ind(X, beta_1, lambda_1, epsilon)
x2 <- create_ind(X, beta_2, lambda_2, epsilon)
x3 <- create_ind(X, beta_3, lambda_2, epsilon)

z1 <- create_ind(Z, beta_1, lambda_1, epsilon)
z2 <- create_ind(Z, beta_2, lambda_2, epsilon)
z3 <- create_ind(Z, beta_3, lambda_2, epsilon)

y1 <- create_ind(Y, beta_1, lambda_1, epsilon)
y2 <- create_ind(Y, beta_2, lambda_2, epsilon)
y3 <- create_ind(Y, beta_2, lambda_2, epsilon)


data.quadratic <- data.frame(
   x1, x2, x3,
   z1, z2, z3,
   y1, y2, y3
)
```

```{r}
model <- '
  X =~ x1 + x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

  Y ~ X + Z + X:X + Z:Z + X:Z
'

fit <- modsem(model, data = data.quadratic, method = "qml")
summary(fit)
```
\normalsize

## 2D Plot

\scriptsize
```{r}
plot_interaction(x = "X", z = "Z", y = "Y", model = fit, vals_z = c(-1, 0, 1))
```
\normalsize

## 3D (Response Surface) Plot

\scriptsize
```{r, eval = FALSE}
plot_surface(x = "X", z = "Z", y = "Y", model = fit,
            colorscale = "Greys", grid = TRUE, grid_color = "black")
```
![](images/surface-plot-2.png){width=80%}
\normalsize

\tiny
## References
